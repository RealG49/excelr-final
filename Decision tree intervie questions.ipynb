{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d471eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "\n",
       "# **1. Common Hyperparameters of Decision Tree Models and Their Effects**\n",
       "\n",
       "## **1.1 max_depth**\n",
       "- Defines the maximum depth of the tree.\n",
       "- **Higher depth**: Captures complex patterns but can lead to **overfitting**.\n",
       "- **Lower depth**: Generalizes better but might cause **underfitting**.\n",
       "\n",
       "## **1.2 min_samples_split**\n",
       "- The minimum number of samples required to split an internal node.\n",
       "- **Higher value**: Prevents frequent splits and reduces overfitting.\n",
       "- **Lower value**: Allows more splits, making the model more complex.\n",
       "\n",
       "## **1.3 min_samples_leaf**\n",
       "- The minimum number of samples required in a leaf node.\n",
       "- Higher values create smoother decision boundaries.\n",
       "\n",
       "## **1.4 max_features**\n",
       "- Number of features considered for each split.\n",
       "- **Lower values**: Increase randomness, reducing overfitting.\n",
       "- **Higher values**: Improve accuracy but may overfit.\n",
       "\n",
       "## **1.5 criterion**\n",
       "- The function that measures split quality.\n",
       "  - `\"gini\"`: Uses Gini Impurity.\n",
       "  - `\"entropy\"`: Uses Information Gain.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Jupyter Notebook Markdown Cells for Theoretical Explanation\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "theory = \"\"\"\n",
    "# **1. Common Hyperparameters of Decision Tree Models and Their Effects**\n",
    "\n",
    "## **1.1 max_depth**\n",
    "- Defines the maximum depth of the tree.\n",
    "- **Higher depth**: Captures complex patterns but can lead to **overfitting**.\n",
    "- **Lower depth**: Generalizes better but might cause **underfitting**.\n",
    "\n",
    "## **1.2 min_samples_split**\n",
    "- The minimum number of samples required to split an internal node.\n",
    "- **Higher value**: Prevents frequent splits and reduces overfitting.\n",
    "- **Lower value**: Allows more splits, making the model more complex.\n",
    "\n",
    "## **1.3 min_samples_leaf**\n",
    "- The minimum number of samples required in a leaf node.\n",
    "- Higher values create smoother decision boundaries.\n",
    "\n",
    "## **1.4 max_features**\n",
    "- Number of features considered for each split.\n",
    "- **Lower values**: Increase randomness, reducing overfitting.\n",
    "- **Higher values**: Improve accuracy but may overfit.\n",
    "\n",
    "## **1.5 criterion**\n",
    "- The function that measures split quality.\n",
    "  - `\"gini\"`: Uses Gini Impurity.\n",
    "  - `\"entropy\"`: Uses Information Gain.\n",
    "\"\"\"\n",
    "\n",
    "display(Markdown(theory))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a322d4ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Difference Between Label Encoding and One-Hot Encoding\n",
      "\n",
      "1. Definition:\n",
      "   - Label Encoding: Converts categorical values into numerical labels.\n",
      "   - One-Hot Encoding: Creates binary (0/1) columns for each category.\n",
      "\n",
      "2. Example:\n",
      "   - Label Encoding: ['Red', 'Blue', 'Green'] → [0, 1, 2]\n",
      "   - One-Hot Encoding: Red → [1, 0, 0], Blue → [0, 1, 0], Green → [0, 0, 1]\n",
      "\n",
      "3. When to Use?\n",
      "   - Label Encoding: When the categorical feature has an ordinal relationship.\n",
      "   - One-Hot Encoding: When categories are non-ordinal (no ranking).\n",
      "\n",
      "4. Impact on Model:\n",
      "   - Label Encoding: May introduce unintended ordinal relationships.\n",
      "   - One-Hot Encoding: Increases feature space, leading to higher memory usage.\n",
      "\n",
      "5. Best for:\n",
      "   - Label Encoding: Tree-based models (like Decision Trees, Random Forest).\n",
      "   - One-Hot Encoding: Linear models, Neural Networks.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the differences\n",
    "text = \"\"\"\n",
    "Difference Between Label Encoding and One-Hot Encoding\n",
    "\n",
    "1. Definition:\n",
    "   - Label Encoding: Converts categorical values into numerical labels.\n",
    "   - One-Hot Encoding: Creates binary (0/1) columns for each category.\n",
    "\n",
    "2. Example:\n",
    "   - Label Encoding: ['Red', 'Blue', 'Green'] → [0, 1, 2]\n",
    "   - One-Hot Encoding: Red → [1, 0, 0], Blue → [0, 1, 0], Green → [0, 0, 1]\n",
    "\n",
    "3. When to Use?\n",
    "   - Label Encoding: When the categorical feature has an ordinal relationship.\n",
    "   - One-Hot Encoding: When categories are non-ordinal (no ranking).\n",
    "\n",
    "4. Impact on Model:\n",
    "   - Label Encoding: May introduce unintended ordinal relationships.\n",
    "   - One-Hot Encoding: Increases feature space, leading to higher memory usage.\n",
    "\n",
    "5. Best for:\n",
    "   - Label Encoding: Tree-based models (like Decision Trees, Random Forest).\n",
    "   - One-Hot Encoding: Linear models, Neural Networks.\n",
    "\"\"\"\n",
    "\n",
    "# Print the text\n",
    "print(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c07df8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
